{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOfVHwwA5rENDeweVb26MY7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63BT4N7KPXDc","executionInfo":{"status":"ok","timestamp":1747502459484,"user_tz":-360,"elapsed":123,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"d8335340-31a1-4829-9a7e-32d994ba5602"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n","        [0.8854, 0.5739, 0.2666, 0.6274],\n","        [0.2696, 0.4414, 0.2969, 0.8317]])\n","tensor([[False, False, False, False],\n","        [False, False, False, False],\n","        [False, False, False, False]])\n"]}],"source":["import torch\n","RANDOM_SEED=42\n","torch.manual_seed(RANDOM_SEED)\n","\n","random_tensor_c = torch.rand(3,4)\n","random_tensor_d = torch.rand(3,4)\n","\n","print(random_tensor_c)\n","print(random_tensor_d)\n","print(random_tensor_c == random_tensor_d)\n"]},{"cell_type":"code","source":["import torch\n","RANDOM_SEED=42\n","torch.manual_seed(RANDOM_SEED)\n","\n","random_tensor_c = torch.rand(3,4)\n","\n","torch.manual_seed(RANDOM_SEED)\n","\n","random_tensor_d = torch.rand(3,4)\n","\n","print(random_tensor_c)\n","print(random_tensor_d)\n","print(random_tensor_c == random_tensor_d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5MbliwNQlmk","executionInfo":{"status":"ok","timestamp":1747502620362,"user_tz":-360,"elapsed":67,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"b6830388-71f7-46b9-c9be-12004e5b7164"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","tensor([[True, True, True, True],\n","        [True, True, True, True],\n","        [True, True, True, True]])\n"]}]},{"cell_type":"markdown","source":["GPU = faster computation on numbers, thanks to CUDA +NVIDIA +PyTorch"],"metadata":{"id":"QQCGa5KMUKWM"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7jtK-P-ZRWx","executionInfo":{"status":"ok","timestamp":1747504796062,"user_tz":-360,"elapsed":184,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"fd905c4f-ac60-4855-e77a-0c7dac58c104"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat May 17 17:59:55 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["# Check for GPU access with Pytorch"],"metadata":{"id":"swOKqQVxaMD1"}},{"cell_type":"code","source":["import torch\n","\n","if torch.cuda.is_available():\n","    print(\"CUDA is available!\")\n","else:\n","    print(\"CUDA is not available.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kzu0RR4fZSIZ","executionInfo":{"status":"ok","timestamp":1747504970809,"user_tz":-360,"elapsed":3987,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"a2111238-08b7-4bdc-e6a9-35d8ab4c470f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available!\n"]}]},{"cell_type":"code","source":["# setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"_UWOR0Vraar8","executionInfo":{"status":"ok","timestamp":1747505130770,"user_tz":-360,"elapsed":44,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"4e340739-144f-4606-b843-f0cdaee18630"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["torch.cuda.device_count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzOZCOATbCt6","executionInfo":{"status":"ok","timestamp":1747505199238,"user_tz":-360,"elapsed":89,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"26eb454f-124d-4fff-c171-fd5cfea84699"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# Create a tensor (default on the CPU)\n","tensor = torch.tensor([1, 2, 3])\n","\n","# Tensor not on GPU\n","print( tensor, tensor.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyk8UmWvbR0T","executionInfo":{"status":"ok","timestamp":1747505798889,"user_tz":-360,"elapsed":1298,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"244b39fe-21ee-4fb5-feef-932a73cf2112"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) cpu\n"]}]},{"cell_type":"code","source":["# Move tensor to GPu (if available)\n","\n","tensor_on_gpu = tensor.to(device)\n","tensor_on_gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlD1lIpadW3w","executionInfo":{"status":"ok","timestamp":1747505922532,"user_tz":-360,"elapsed":192,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"4d0a2522-378f-47dc-d559-b9dff2d0e8db"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3], device='cuda:0')"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# Moving tensors back to the CPU"],"metadata":{"id":"yNOHEoT0e1LA"}},{"cell_type":"code","source":["# If tensor is on GPU, cant't transform it to numpy\n","tensor_on_gpu.numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"m8ScpG67gVi6","executionInfo":{"status":"error","timestamp":1747506539314,"user_tz":-360,"elapsed":41,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"f2525bb5-c8f4-464b-f48e-11eb67e38a74"},"execution_count":10,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e50d2bc02281>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, cant't transform it to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}]},{"cell_type":"code","source":["# to fix the GPU tensor with NumPy issue,we can first set it to the cpu\n","tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n","tensor_back_on_cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6wVLauxgyUn","executionInfo":{"status":"ok","timestamp":1747506774340,"user_tz":-360,"elapsed":19,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"b320ed02-9ac5-4d00-8d4e-f008cc86ea3b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["tensor_on_gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s69yrG4BhdaQ","executionInfo":{"status":"ok","timestamp":1747506822521,"user_tz":-360,"elapsed":49,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"e9922553-3432-4249-fb9a-eb8b50dfc98c"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3], device='cuda:0')"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["\n","device = \"cpu\" if torch.cuda.is_available() else \"cuda\"\n","tensor_on_cpu= tensor_on_gpu.to(device)\n","print(tensor_on_cpu,tensor_on_cpu.device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oHyzhKMeD9r","executionInfo":{"status":"ok","timestamp":1747510368841,"user_tz":-360,"elapsed":24,"user":{"displayName":"mijan Rahaman","userId":"16084407762113582784"}},"outputId":"93a6aab1-09a7-47b3-92b8-1de67620d1ec"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) cpu\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"o7qgAYZ7ftQE"},"execution_count":null,"outputs":[]}]}